#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
M3Uæ’­æ”¾åˆ—è¡¨å¤„ç†å·¥å…·
ç”¨äºè§£æã€åˆå¹¶ã€æ¯”è¾ƒå’Œå¯¼å‡ºM3Uæ’­æ”¾åˆ—è¡¨æ–‡ä»¶
"""

import re
import json
import csv
import argparse
import sys
import requests
from pathlib import Path
from typing import List, Dict, Optional, Set, Tuple
from collections import defaultdict
from urllib.parse import quote


class ChannelConfigLoader:
    """é¢‘é“é…ç½®åŠ è½½å™¨"""
    
    @staticmethod
    def load(config_file: str) -> Tuple[Dict, Dict, Dict]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶ä¸­çš„CHANNEL_CATEGORIESå’ŒCHANNEL_MAPPING
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            (channel_categories, channel_mapping, alias_map) å…ƒç»„
        """
        config_path = Path(config_file)
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        local_vars = {}
        
        # å¤„ç†åŒ…å« data æ¨¡å—å¯¼å…¥çš„æƒ…å†µ
        if 'from data import' in content or 'import data' in content:
            data_file = config_path.parent / 'data.py'
            if data_file.exists():
                with open(data_file, 'r', encoding='utf-8') as df:
                    data_content = df.read()
                exec(data_content, {}, local_vars)
                exec(content, local_vars, local_vars)
            else:
                import sys
                sys.path.insert(0, str(config_path.parent))
                exec(content, {}, local_vars)
        else:
            exec(content, {}, local_vars)
        
        channel_categories = local_vars.get('CHANNEL_CATEGORIES', {})
        channel_mapping = local_vars.get('CHANNEL_MAPPING', {})
        
        # æ„å»ºåˆ«ååˆ°æ ‡å‡†åçš„æ˜ å°„
        alias_map = ChannelConfigLoader._build_alias_map(channel_mapping)
        
        return channel_categories, channel_mapping, alias_map
    
    @staticmethod
    def _build_alias_map(channel_mapping: Dict) -> Dict[str, str]:
        """æ„å»ºåˆ«ååˆ°æ ‡å‡†åçš„æ˜ å°„"""
        alias_map = {}
        for standard_name, aliases in channel_mapping.items():
            for alias in aliases:
                alias_map[alias] = standard_name
            alias_map[standard_name] = standard_name
        return alias_map


class RTPFileLoader:
    """RTPæ–‡ä»¶åŠ è½½å™¨"""
    
    @staticmethod
    def load(rtp_path: Path) -> Dict[str, List[str]]:
        """
        åŠ è½½RTPæ–‡ä»¶ï¼Œè¿”å›é¢‘é“ååˆ°RTP URLåˆ—è¡¨çš„æ˜ å°„
        
        Args:
            rtp_path: RTPæ–‡ä»¶è·¯å¾„
            
        Returns:
            é¢‘é“ååˆ°URLåˆ—è¡¨çš„å­—å…¸
        """
        rtp_channels = defaultdict(list)
        
        with open(rtp_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or ',' not in line:
                    continue
                
                parts = line.split(',', 1)
                if len(parts) == 2:
                    ch_name = parts[0].strip()
                    rtp_url = parts[1].strip()
                    rtp_channels[ch_name].append(rtp_url)
        
        return dict(rtp_channels)


class ChannelMapper:
    """é¢‘é“åç§°æ˜ å°„å™¨"""
    
    def __init__(self, channel_mapping: Dict, channel_categories: Dict):
        """
        åˆå§‹åŒ–æ˜ å°„å™¨
        
        Args:
            channel_mapping: é¢‘é“æ˜ å°„é…ç½®
            channel_categories: é¢‘é“åˆ†ç±»é…ç½®
        """
        self.channel_mapping = channel_mapping
        self.channel_categories = channel_categories
        self.name_to_standard = ChannelConfigLoader._build_alias_map(channel_mapping)
    
    def normalize_name(self, name: str) -> str:
        """å°†é¢‘é“åæ ‡å‡†åŒ–"""
        return self.name_to_standard.get(name, name)
    
    def find_group_title(self, channel_name: str) -> str:
        """æ ¹æ®é¢‘é“åç§°æŸ¥æ‰¾å¯¹åº”çš„åˆ†ç»„"""
        for group_title, channels in self.channel_categories.items():
            if channel_name in channels:
                return group_title
        return 'å…¶ä»–'
    
    def build_rtp_mapping(self, rtp_channels: Dict[str, List[str]]) -> Tuple[Dict, Dict]:
        """
        æ„å»ºRTPé¢‘é“ååˆ°æ ‡å‡†åçš„æ˜ å°„
        
        Args:
            rtp_channels: RTPé¢‘é“å­—å…¸
            
        Returns:
            (rtp_to_standard, standard_to_rtp) å…ƒç»„
        """
        rtp_to_standard = {}
        for rtp_name in rtp_channels.keys():
            standard = self.normalize_name(rtp_name)
            rtp_to_standard[rtp_name] = standard
        
        standard_to_rtp = defaultdict(list)
        for rtp_name, standard in rtp_to_standard.items():
            standard_to_rtp[standard].append(rtp_name)
        
        return rtp_to_standard, dict(standard_to_rtp)


class M3UPlaylist:
    """M3Uæ’­æ”¾åˆ—è¡¨å¤„ç†å™¨"""
    
    def __init__(self, file_path: str):
        """
        åˆå§‹åŒ–æ’­æ”¾åˆ—è¡¨å¤„ç†å™¨
        
        Args:
            file_path: M3Uæ–‡ä»¶è·¯å¾„
        """
        self.file_path = Path(file_path)
        self.channels: List[Dict[str, str]] = []
        self.header_info: Dict[str, str] = {}
    
    def parse(self) -> List[Dict[str, str]]:
        """
        è§£æM3Uæ–‡ä»¶
        
        Returns:
            é¢‘é“ä¿¡æ¯åˆ—è¡¨
        """
        if not self.file_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.file_path}")
        
        with open(self.file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        current_channel: Optional[Dict[str, str]] = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            if line.startswith('#EXTM3U'):
                self._parse_header(line)
                continue
            
            if line.startswith('#EXTINF'):
                current_channel = self._parse_extinf(line)
                continue
            
            if self._is_url_line(line):
                if current_channel:
                    current_channel['url'] = line
                    self.channels.append(current_channel)
                    current_channel = None
        
        return self.channels
    
    def _is_url_line(self, line: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºURLè¡Œ"""
        return any(line.startswith(prefix) for prefix in 
                  ['http://', 'https://', 'rtp://', 'udp://'])
    
    def _parse_header(self, line: str):
        """è§£æM3Uæ–‡ä»¶å¤´"""
        name_match = re.search(r'name="([^"]+)"', line)
        if name_match:
            self.header_info['name'] = name_match.group(1)
        
        tvg_url_match = re.search(r'x-tvg-url="([^"]+)"', line)
        if tvg_url_match:
            self.header_info['x-tvg-url'] = tvg_url_match.group(1)
    
    def _parse_extinf(self, line: str) -> Dict[str, str]:
        """è§£æ #EXTINF è¡Œ"""
        channel = {}
        
        # æå–å±æ€§
        attrs = {
            'tvg-id': r'tvg-id="([^"]*)"',
            'tvg-name': r'tvg-name="([^"]*)"',
            'tvg-logo': r'tvg-logo="([^"]*)"',
            'group-title': r'group-title="([^"]*)"'
        }
        
        for key, pattern in attrs.items():
            match = re.search(pattern, line)
            if match:
                channel[key] = match.group(1)
        
        # æå–é¢‘é“åç§°ï¼ˆæœ€åä¸€ä¸ªé€—å·åçš„å†…å®¹ï¼‰
        parts = line.split(',')
        if len(parts) > 1:
            channel['channel-name'] = parts[-1].strip()
        
        # æå–æ—¶é•¿
        duration_match = re.match(r'#EXTINF:(-?\d+)', line)
        if duration_match:
            channel['duration'] = duration_match.group(1)
        
        return channel
    
    def merge_with_rtp(self, rtp_file_path: str, 
                      rtp_dir: str = "source/zubo/rtp",
                      config_file: str = "source/zubo/data.py",
                      filter_only: bool = False) -> List[Dict[str, str]]:
        """
        ä½¿ç”¨RTPæ–‡ä»¶æ›¿æ¢M3Uä¸­çš„é“¾æ¥ï¼Œå¹¶é‡æ–°ç»„ç»‡é¢‘é“ä¿¡æ¯
        
        Args:
            rtp_file_path: RTPæ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºrtp_dirï¼‰
            rtp_dir: RTPæ–‡ä»¶ç›®å½•
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
            filter_only: å¦‚æœä¸ºTrueï¼Œåªä¿ç•™RTPæ–‡ä»¶ä¸­å­˜åœ¨çš„é¢‘é“ï¼ˆåˆ é™¤æ¨¡æ¿ä¸­æ²¡æœ‰çš„é¢‘é“ï¼‰
            
        Returns:
            é‡æ–°ç»„ç»‡åçš„é¢‘é“åˆ—è¡¨
        """
        # åŠ è½½é…ç½®å’ŒRTPæ–‡ä»¶
        channel_categories, channel_mapping, _ = ChannelConfigLoader.load(config_file)
        mapper = ChannelMapper(channel_mapping, channel_categories)
        
        rtp_path = Path(rtp_dir) / rtp_file_path
        if not rtp_path.exists():
            raise FileNotFoundError(f"RTPæ–‡ä»¶ä¸å­˜åœ¨: {rtp_path}")
        
        rtp_channels = RTPFileLoader.load(rtp_path)
        rtp_to_standard, standard_to_rtp = mapper.build_rtp_mapping(rtp_channels)
        
        # å¤„ç†ç°æœ‰é¢‘é“
        processed_channels = []
        matched_rtp_names = set()
        
        for channel in self.channels:
            new_channel = self._process_channel_with_rtp(
                channel, mapper, rtp_channels, rtp_to_standard, 
                standard_to_rtp, matched_rtp_names
            )
            
            # å¦‚æœfilter_onlyä¸ºTrueï¼Œåªä¿ç•™åŒ¹é…çš„é¢‘é“ï¼ˆæœ‰URLä¸”URLæ¥è‡ªRTPæ–‡ä»¶ï¼‰
            if filter_only:
                if new_channel and new_channel.get('url'):
                    # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŒ¹é…åˆ°RTPé¢‘é“ï¼ˆmatched_rtp_namesä¸­æœ‰è®°å½•ï¼‰
                    tvg_name = channel.get('tvg-name') or channel.get('channel-name', '')
                    standard_name = mapper.normalize_name(tvg_name)
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ¹é…æˆåŠŸ
                    is_matched = False
                    if standard_name in standard_to_rtp:
                        is_matched = True
                    elif standard_name in rtp_channels:
                        is_matched = True
                    elif tvg_name in rtp_channels:
                        is_matched = True
                    
                    if is_matched:
                        processed_channels.append(new_channel)
            else:
                if new_channel:
                    processed_channels.append(new_channel)
        
        # æ·»åŠ æœªåŒ¹é…çš„RTPé¢‘é“ï¼ˆä»…åœ¨éè¿‡æ»¤æ¨¡å¼ä¸‹ï¼‰
        if not filter_only:
            unmatched_rtp = set(rtp_channels.keys()) - matched_rtp_names
            for rtp_name in unmatched_rtp:
                standard_name = rtp_to_standard.get(rtp_name, rtp_name)
                new_channel = {
                    'tvg-name': standard_name,
                    'tvg-logo': '',
                    'group-title': mapper.find_group_title(standard_name),
                    'channel-name': standard_name,
                    'url': rtp_channels[rtp_name][0],
                    'duration': '-1'
                }
                processed_channels.append(new_channel)
        
        # å»é™¤é‡å¤çš„URLï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªå‡ºç°çš„ï¼Œä¼˜å…ˆä¿ç•™æœ‰logoçš„ï¼‰
        seen_urls = {}
        deduplicated_channels = []
        
        for channel in processed_channels:
            url = channel.get('url', '')
            if not url:
                continue
            
            if url not in seen_urls:
                # ç¬¬ä¸€æ¬¡å‡ºç°ï¼Œç›´æ¥æ·»åŠ 
                seen_urls[url] = channel
                deduplicated_channels.append(channel)
            else:
                # é‡å¤URLï¼Œä¼˜å…ˆä¿ç•™æœ‰logoçš„é¢‘é“
                existing = seen_urls[url]
                if not existing.get('tvg-logo') and channel.get('tvg-logo'):
                    # æ›¿æ¢ä¸ºæœ‰logoçš„é¢‘é“
                    idx = deduplicated_channels.index(existing)
                    deduplicated_channels[idx] = channel
                    seen_urls[url] = channel
        
        # é‡æ–°ç¼–å·
        for idx, channel in enumerate(deduplicated_channels, 1):
            channel['tvg-id'] = str(idx)
        
        self.channels = deduplicated_channels
        return deduplicated_channels
    
    def _process_channel_with_rtp(self, channel: Dict, mapper: ChannelMapper,
                                  rtp_channels: Dict, rtp_to_standard: Dict,
                                  standard_to_rtp: Dict, matched_rtp_names: Set) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªé¢‘é“ä¸RTPçš„åŒ¹é…"""
        tvg_name = channel.get('tvg-name') or channel.get('channel-name', '')
        standard_name = mapper.normalize_name(tvg_name)
        
        # æŸ¥æ‰¾åŒ¹é…çš„RTPé¢‘é“
        matched_rtp = None
        matched_rtp_key = None
        
        if standard_name in standard_to_rtp:
            rtp_key = standard_to_rtp[standard_name][0]
            matched_rtp = rtp_channels[rtp_key]
            matched_rtp_key = rtp_key
            matched_rtp_names.add(rtp_key)
        elif standard_name in rtp_channels:
            matched_rtp = rtp_channels[standard_name]
            matched_rtp_key = standard_name
            matched_rtp_names.add(standard_name)
        else:
            # å°è¯•ç›´æ¥åŒ¹é…åŸå§‹åç§°
            if tvg_name in rtp_channels:
                matched_rtp = rtp_channels[tvg_name]
                matched_rtp_key = tvg_name
                matched_rtp_names.add(tvg_name)
        
        # åˆ›å»ºæ–°é¢‘é“ä¿¡æ¯
        new_channel = channel.copy()
        
        if matched_rtp:
            new_channel['url'] = matched_rtp[0]
        
        if standard_name:
            new_channel['tvg-name'] = standard_name
            new_channel['group-title'] = mapper.find_group_title(standard_name)
            if not new_channel.get('channel-name'):
                new_channel['channel-name'] = standard_name
        else:
            if not new_channel.get('group-title'):
                new_channel['group-title'] = 'å…¶ä»–'
            if not new_channel.get('channel-name'):
                new_channel['channel-name'] = new_channel.get('tvg-name', '')
        
        return new_channel
    
    def export_to_json(self, output_path: Optional[str] = None) -> str:
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        output_path = self._get_output_path(output_path, '.json')
        
        data = {
            'header': self.header_info,
            'channels': self.channels
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        return str(output_path)
    
    def export_to_csv(self, output_path: Optional[str] = None) -> str:
        """å¯¼å‡ºä¸ºCSVæ ¼å¼"""
        output_path = self._get_output_path(output_path, '.csv')
        
        with open(output_path, 'w', encoding='utf-8', newline='') as f:
            if not self.channels:
                return str(output_path)
            
            fieldnames = ['tvg-name', 'tvg-logo', 'tvg-id', 'group-title', 'channel-name', 'url']
            writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
            writer.writeheader()
            
            for channel in self.channels:
                writer.writerow(channel)
        
        return str(output_path)
    
    def generate_m3u(self, output_path: Optional[str] = None, 
                     url_mapping: Optional[Dict[str, str]] = None) -> str:
        """é‡æ–°ç”ŸæˆM3Uæ–‡ä»¶"""
        output_path = self._get_output_path(output_path, '.generated.m3u')
        
        with open(output_path, 'w', encoding='utf-8') as f:
            self._write_header(f)
            self._write_channels(f, url_mapping)
        
        return str(output_path)
    
    def _get_output_path(self, output_path: Optional[str], suffix: str) -> Path:
        """è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„"""
        if output_path is None:
            return self.file_path.with_suffix(suffix)
        return Path(output_path)
    
    def _write_header(self, f):
        """å†™å…¥M3Uæ–‡ä»¶å¤´"""
        if self.header_info.get('name'):
            f.write(f'#EXTM3U name="{self.header_info["name"]}"\n')
        if self.header_info.get('x-tvg-url'):
            f.write(f'#EXTM3U x-tvg-url="{self.header_info["x-tvg-url"]}"\n')
    
    def _write_channels(self, f, url_mapping: Optional[Dict[str, str]]):
        """å†™å…¥é¢‘é“ä¿¡æ¯"""
        for channel in self.channels:
            # å¦‚æœ tvg-logo ä¸ºç©ºï¼Œå°è¯•ä»ä¸¤ä¸ª URL è·å– logo
            if not channel.get('tvg-logo'):
                logo_url = self._try_get_logo_url(channel.get('tvg-name', ''))
                if logo_url:
                    channel['tvg-logo'] = logo_url
            
            f.write(self._build_extinf_line(channel) + '\n')
            
            url = self._get_channel_url(channel, url_mapping)
            if url:
                f.write(url + '\n')
    
    def _build_extinf_line(self, channel: Dict) -> str:
        """æ„å»º #EXTINF è¡Œ"""
        duration = channel.get('duration', '-1')
        extinf = f'#EXTINF:{duration}'
        
        attrs = []
        for key in ['tvg-id', 'tvg-name', 'tvg-logo', 'group-title']:
            if channel.get(key):
                attrs.append(f'{key}="{channel[key]}"')
        
        if attrs:
            extinf += ',' + ' '.join(attrs)
        
        channel_name = channel.get('channel-name', channel.get('tvg-name', ''))
        if channel_name:
            extinf += f',{channel_name}'
        
        return extinf
    
    def _get_channel_url(self, channel: Dict, url_mapping: Optional[Dict[str, str]]) -> str:
        """è·å–é¢‘é“URL"""
        if url_mapping and channel.get('tvg-name') in url_mapping:
            return url_mapping[channel['tvg-name']]
        return channel.get('url', '')
    
    def _check_url_exists(self, url: str, timeout: int = 5) -> bool:
        """
        æ£€æŸ¥ URL æ˜¯å¦å¯ä»¥è®¿é—®
        
        Args:
            url: è¦æ£€æŸ¥çš„ URL
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            å¦‚æœ URL å¯ä»¥è®¿é—®è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        try:
            # å…ˆå°è¯• HEAD è¯·æ±‚ï¼ˆæ›´é«˜æ•ˆï¼‰
            response = requests.head(url, timeout=timeout, allow_redirects=True)
            if response.status_code == 200:
                return True
        except:
            pass
        
        try:
            # å¦‚æœ HEAD è¯·æ±‚å¤±è´¥ï¼Œå°è¯• GET è¯·æ±‚ï¼ˆåªè·å–å¤´éƒ¨ï¼Œä¸ä¸‹è½½å†…å®¹ï¼‰
            response = requests.get(url, timeout=timeout, stream=True, allow_redirects=True)
            # ç«‹å³å…³é—­è¿æ¥ï¼Œä¸ä¸‹è½½å†…å®¹
            response.close()
            return response.status_code == 200
        except:
            return False
    
    def _try_get_logo_url(self, tvg_name: str) -> Optional[str]:
        """
        å°è¯•ä»ä¸¤ä¸ª URL è·å– logo
        
        Args:
            tvg_name: é¢‘é“åç§°ï¼ˆtvg-nameï¼‰
            
        Returns:
            å¦‚æœæ‰¾åˆ°å¯è®¿é—®çš„ logo URLï¼Œè¿”å› URLï¼›å¦åˆ™è¿”å› None
        """
        if not tvg_name:
            return None
        
        # ä¸¤ä¸ª logo URL æ¨¡æ¿ï¼Œå…ˆå°è¯•åŸå§‹åç§°ï¼ˆå…¼å®¹ç°æœ‰æ ¼å¼å¦‚ CCTV5+ï¼‰
        logo_urls = [
            f"https://epg.112114.xyz/logo/{tvg_name}.png",
            f"https://live.fanmingming.com/tv/{tvg_name}.png"
        ]
        
        # å°è¯•æ¯ä¸ª URL
        for logo_url in logo_urls:
            if self._check_url_exists(logo_url):
                return logo_url
        
        # å¦‚æœåŸå§‹åç§°å¤±è´¥ï¼Œå°è¯• URL ç¼–ç çš„ç‰ˆæœ¬ï¼ˆå¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼‰
        encoded_name = quote(tvg_name, safe='')
        encoded_logo_urls = [
            f"https://epg.112114.xyz/logo/{encoded_name}.png",
            f"https://live.fanmingming.com/tv/{encoded_name}.png"
        ]
        
        for logo_url in encoded_logo_urls:
            if self._check_url_exists(logo_url):
                return logo_url
        
        return None
    
    def deduplicate_urls(self) -> Dict:
        """
        å»é™¤é‡å¤çš„URLï¼Œä¿ç•™ç¬¬ä¸€ä¸ªå‡ºç°çš„é¢‘é“ï¼ˆä¼˜å…ˆä¿ç•™æœ‰logoçš„ï¼‰
        
        Returns:
            åŒ…å«å»é‡ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        seen_urls = {}
        deduplicated_channels = []
        removed_count = 0
        removed_channels = []
        
        for channel in self.channels:
            url = channel.get('url', '')
            if not url:
                # æ²¡æœ‰URLçš„é¢‘é“ç›´æ¥ä¿ç•™
                deduplicated_channels.append(channel)
                continue
            
            if url not in seen_urls:
                # ç¬¬ä¸€æ¬¡å‡ºç°ï¼Œç›´æ¥æ·»åŠ 
                seen_urls[url] = channel
                deduplicated_channels.append(channel)
            else:
                # é‡å¤URLï¼Œä¼˜å…ˆä¿ç•™æœ‰logoçš„é¢‘é“
                existing = seen_urls[url]
                existing_has_logo = bool(existing.get('tvg-logo'))
                current_has_logo = bool(channel.get('tvg-logo'))
                
                if not existing_has_logo and current_has_logo:
                    # æ›¿æ¢ä¸ºæœ‰logoçš„é¢‘é“
                    idx = deduplicated_channels.index(existing)
                    removed_channels.append({
                        'name': existing.get('tvg-name', existing.get('channel-name', 'æœªçŸ¥')),
                        'url': url,
                        'reason': 'è¢«æœ‰logoçš„é¢‘é“æ›¿æ¢'
                    })
                    deduplicated_channels[idx] = channel
                    seen_urls[url] = channel
                    removed_count += 1
                else:
                    # ä¿ç•™å·²å­˜åœ¨çš„é¢‘é“
                    removed_channels.append({
                        'name': channel.get('tvg-name', channel.get('channel-name', 'æœªçŸ¥')),
                        'url': url,
                        'reason': 'URLé‡å¤ï¼Œä¿ç•™ç¬¬ä¸€ä¸ª'
                    })
                    removed_count += 1
        
        original_count = len(self.channels)
        self.channels = deduplicated_channels
        
        return {
            'original_count': original_count,
            'deduplicated_count': len(deduplicated_channels),
            'removed_count': removed_count,
            'removed_channels': removed_channels
        }
    
    def get_summary(self) -> Dict:
        """è·å–è§£ææ‘˜è¦ä¿¡æ¯"""
        total_channels = len(self.channels)
        channels_with_name = sum(1 for c in self.channels if c.get('tvg-name'))
        channels_with_logo = sum(1 for c in self.channels if c.get('tvg-logo'))
        channels_with_url = sum(1 for c in self.channels if c.get('url'))
        
        group_titles = defaultdict(int)
        for channel in self.channels:
            group = channel.get('group-title', 'æœªåˆ†ç±»')
            group_titles[group] += 1
        
        return {
            'total_channels': total_channels,
            'channels_with_name': channels_with_name,
            'channels_with_logo': channels_with_logo,
            'channels_with_url': channels_with_url,
            'group_titles': dict(group_titles)
        }


class M3UComparator:
    """M3Uæ–‡ä»¶æ¯”è¾ƒå™¨"""
    
    @staticmethod
    def compare(file1_path: str, file2_path: str, 
                output_file: Optional[str] = None,
                config_file: str = "source/zubo/data.py") -> Dict:
        """
        æ¯”è¾ƒä¸¤ä¸ªM3Uæ–‡ä»¶çš„URLå·®å¼‚
        
        Args:
            file1_path: ç¬¬ä¸€ä¸ªM3Uæ–‡ä»¶è·¯å¾„
            file2_path: ç¬¬äºŒä¸ªM3Uæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºå·®å¼‚æŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«å·®å¼‚ä¿¡æ¯çš„å­—å…¸
        """
        playlist1 = M3UPlaylist(file1_path)
        playlist2 = M3UPlaylist(file2_path)
        
        channels1 = playlist1.parse()
        channels2 = playlist2.parse()
        
        # åŠ è½½é…ç½®
        try:
            _, channel_mapping, _ = ChannelConfigLoader.load(config_file)
            mapper = ChannelMapper(channel_mapping, {})
        except:
            mapper = ChannelMapper({}, {})
        
        # æ„å»ºé¢‘é“æ˜ å°„
        channels1_map = M3UComparator._build_channel_map(channels1, mapper)
        channels2_map = M3UComparator._build_channel_map(channels2, mapper)
        
        # æ¯”è¾ƒå·®å¼‚
        result = M3UComparator._compare_maps(channels1_map, channels2_map, 
                                            file1_path, file2_path, 
                                            len(channels1), len(channels2))
        
        # ç”ŸæˆæŠ¥å‘Š
        if output_file:
            M3UComparator._write_report(result, output_file)
        
        return result
    
    @staticmethod
    def _build_channel_map(channels: List[Dict], mapper: ChannelMapper) -> Dict:
        """æ„å»ºé¢‘é“ååˆ°é¢‘é“ä¿¡æ¯çš„æ˜ å°„"""
        channel_map = {}
        for ch in channels:
            tvg_name = ch.get('tvg-name', '') or ch.get('channel-name', '')
            if tvg_name:
                standard_name = mapper.normalize_name(tvg_name)
                if standard_name not in channel_map:
                    channel_map[standard_name] = []
                channel_map[standard_name].append({
                    'url': ch.get('url', ''),
                    'tvg-name': ch.get('tvg-name', ''),
                    'channel-name': ch.get('channel-name', ''),
                    'group-title': ch.get('group-title', ''),
                    'tvg-logo': ch.get('tvg-logo', '')
                })
        return channel_map
    
    @staticmethod
    def _compare_maps(map1: Dict, map2: Dict, file1: str, file2: str,
                     count1: int, count2: int) -> Dict:
        """æ¯”è¾ƒä¸¤ä¸ªé¢‘é“æ˜ å°„"""
        differences = []
        only_in_file1 = []
        only_in_file2 = []
        same_urls = []
        
        all_names = set(map1.keys()) | set(map2.keys())
        
        for name in sorted(all_names):
            ch1_list = map1.get(name, [])
            ch2_list = map2.get(name, [])
            
            if not ch1_list:
                for ch2 in ch2_list:
                    only_in_file2.append({
                        'name': name,
                        'url': ch2['url'],
                        'tvg-name': ch2['tvg-name'],
                        'group-title': ch2['group-title']
                    })
            elif not ch2_list:
                for ch1 in ch1_list:
                    only_in_file1.append({
                        'name': name,
                        'url': ch1['url'],
                        'tvg-name': ch1['tvg-name'],
                        'group-title': ch1['group-title']
                    })
            else:
                urls1 = {ch['url'] for ch in ch1_list}
                urls2 = {ch['url'] for ch in ch2_list}
                
                if urls1 == urls2:
                    same_urls.append({
                        'name': name,
                        'url': list(urls1)[0] if urls1 else '',
                        'tvg-name': ch1_list[0].get('tvg-name', ''),
                        'group-title': ch1_list[0].get('group-title', '')
                    })
                else:
                    differences.append({
                        'name': name,
                        'file1_urls': sorted(list(urls1)),
                        'file2_urls': sorted(list(urls2)),
                        'tvg-name': ch1_list[0].get('tvg-name', ''),
                        'group-title': ch1_list[0].get('group-title', '')
                    })
        
        return {
            'file1': file1,
            'file2': file2,
            'file1_total': count1,
            'file2_total': count2,
            'differences': differences,
            'only_in_file1': only_in_file1,
            'only_in_file2': only_in_file2,
            'same_urls': same_urls,
            'diff_count': len(differences),
            'only_file1_count': len(only_in_file1),
            'only_file2_count': len(only_in_file2),
            'same_count': len(same_urls)
        }
    
    @staticmethod
    def _write_report(result: Dict, output_file: str):
        """å†™å…¥æ¯”è¾ƒæŠ¥å‘Š"""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("M3Uæ–‡ä»¶URLå·®å¼‚æ¯”è¾ƒæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"æ–‡ä»¶1: {result['file1']}\n")
            f.write(f"æ–‡ä»¶2: {result['file2']}\n\n")
            f.write("ç»Ÿè®¡ä¿¡æ¯:\n")
            f.write(f"  æ–‡ä»¶1æ€»é¢‘é“æ•°: {result['file1_total']}\n")
            f.write(f"  æ–‡ä»¶2æ€»é¢‘é“æ•°: {result['file2_total']}\n")
            f.write(f"  URLç›¸åŒçš„é¢‘é“: {result['same_count']}\n")
            f.write(f"  URLä¸åŒçš„é¢‘é“: {result['diff_count']}\n")
            f.write(f"  ä»…åœ¨æ–‡ä»¶1ä¸­çš„é¢‘é“: {result['only_file1_count']}\n")
            f.write(f"  ä»…åœ¨æ–‡ä»¶2ä¸­çš„é¢‘é“: {result['only_file2_count']}\n\n")
            
            if result['differences']:
                f.write("=" * 60 + "\n")
                f.write(f"URLä¸åŒçš„é¢‘é“ ({len(result['differences'])}ä¸ª):\n")
                f.write("=" * 60 + "\n\n")
                for diff in result['differences']:
                    f.write(f"é¢‘é“åç§°: {diff['name']}\n")
                    f.write(f"  åˆ†ç»„: {diff.get('group-title', 'N/A')}\n")
                    f.write("  æ–‡ä»¶1 URL:\n")
                    for url in diff['file1_urls']:
                        f.write(f"    - {url}\n")
                    f.write("  æ–‡ä»¶2 URL:\n")
                    for url in diff['file2_urls']:
                        f.write(f"    - {url}\n")
                    f.write("\n")
            
            if result['only_in_file1']:
                f.write("=" * 60 + "\n")
                f.write(f"ä»…åœ¨æ–‡ä»¶1ä¸­çš„é¢‘é“ ({len(result['only_in_file1'])}ä¸ª):\n")
                f.write("=" * 60 + "\n\n")
                for ch in result['only_in_file1']:
                    f.write(f"é¢‘é“åç§°: {ch['name']}\n")
                    f.write(f"  åˆ†ç»„: {ch.get('group-title', 'N/A')}\n")
                    f.write(f"  URL: {ch['url']}\n\n")
            
            if result['only_in_file2']:
                f.write("=" * 60 + "\n")
                f.write(f"ä»…åœ¨æ–‡ä»¶2ä¸­çš„é¢‘é“ ({len(result['only_in_file2'])}ä¸ª):\n")
                f.write("=" * 60 + "\n\n")
                for ch in result['only_in_file2']:
                    f.write(f"é¢‘é“åç§°: {ch['name']}\n")
                    f.write(f"  åˆ†ç»„: {ch.get('group-title', 'N/A')}\n")
                    f.write(f"  URL: {ch['url']}\n\n")


def batch_process_rtp(template_file: str, rtp_dir: str, output_dir: str,
                      config_file: str = "source/zubo/data.py") -> Dict:
    """
    æ‰¹é‡å¤„ç†RTPæ–‡ä»¶ï¼Œä½¿ç”¨æ¨¡æ¿M3Uæ–‡ä»¶åˆå¹¶æ‰€æœ‰RTPæ–‡ä»¶
    
    Args:
        template_file: æ¨¡æ¿M3Uæ–‡ä»¶è·¯å¾„
        rtp_dir: RTPæ–‡ä»¶ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        å¤„ç†ç»“æœå­—å…¸ï¼ŒåŒ…å«æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†ä¿¡æ¯å’Œç¼ºå°‘logoçš„é¢‘é“åˆ—è¡¨
    """
    template_path = Path(template_file)
    rtp_dir_path = Path(rtp_dir)
    output_dir_path = Path(output_dir)
    
    if not template_path.exists():
        raise FileNotFoundError(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_path}")
    if not rtp_dir_path.exists():
        raise FileNotFoundError(f"RTPç›®å½•ä¸å­˜åœ¨: {rtp_dir_path}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir_path.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰RTPæ–‡ä»¶
    rtp_files = list(rtp_dir_path.glob("*.txt"))
    
    results = {
        'processed': [],
        'failed': [],
        'no_logo_channels': {}
    }
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(rtp_files)} ä¸ªRTPæ–‡ä»¶")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir_path}\n")
    
    for rtp_file in sorted(rtp_files):
        try:
            print(f"ğŸ”„ æ­£åœ¨å¤„ç†: {rtp_file.name}")
            
            # åŠ è½½æ¨¡æ¿
            playlist = M3UPlaylist(template_file)
            playlist.parse()
            
            # åˆå¹¶RTPæ–‡ä»¶ï¼ˆåªä¿ç•™RTPä¸­å­˜åœ¨çš„é¢‘é“ï¼‰
            channels = playlist.merge_with_rtp(
                rtp_file.name,
                rtp_dir=str(rtp_dir_path),
                config_file=config_file,
                filter_only=True
            )
            
            # æ£€æŸ¥ç¼ºå°‘logoçš„é¢‘é“
            no_logo_channels = [
                ch.get('tvg-name', ch.get('channel-name', 'æœªçŸ¥'))
                for ch in channels
                if not ch.get('tvg-logo')
            ]
            
            if no_logo_channels:
                results['no_logo_channels'][rtp_file.stem] = no_logo_channels
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            output_file = output_dir_path / f"{rtp_file.stem}.m3u"
            
            # å¯¼å‡ºM3Uæ–‡ä»¶
            playlist.generate_m3u(str(output_file))
            
            results['processed'].append({
                'rtp_file': rtp_file.name,
                'output_file': str(output_file),
                'channel_count': len(channels),
                'no_logo_count': len(no_logo_channels)
            })
            
            print(f"  âœ… å®Œæˆ: {len(channels)} ä¸ªé¢‘é“ï¼Œ{len(no_logo_channels)} ä¸ªç¼ºå°‘logo")
            
        except Exception as e:
            error_msg = f"å¤„ç† {rtp_file.name} å¤±è´¥: {e}"
            results['failed'].append({
                'rtp_file': rtp_file.name,
                'error': str(e)
            })
            print(f"  âŒ {error_msg}")
    
    return results


def batch_process_m3u(input_dir: str, output_dir: str, 
                     dedup: bool = False) -> Dict:
    """
    æ‰¹é‡å¤„ç†M3Uæ–‡ä»¶ï¼Œä»è¾“å…¥ç›®å½•è¯»å–æ‰€æœ‰m3uæ–‡ä»¶ï¼Œå¤„ç†åè¾“å‡ºåˆ°è¾“å‡ºç›®å½•
    
    Args:
        input_dir: è¾“å…¥M3Uæ–‡ä»¶ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        dedup: æ˜¯å¦å»é™¤é‡å¤çš„URL
        
    Returns:
        å¤„ç†ç»“æœå­—å…¸ï¼ŒåŒ…å«æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†ä¿¡æ¯
    """
    input_dir_path = Path(input_dir)
    output_dir_path = Path(output_dir)
    
    if not input_dir_path.exists():
        raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir_path}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir_path.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰M3Uæ–‡ä»¶
    m3u_files = list(input_dir_path.glob("*.m3u"))
    
    results = {
        'processed': [],
        'failed': [],
        'total_channels': 0,
        'channels_with_logo_added': 0
    }
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(m3u_files)} ä¸ªM3Uæ–‡ä»¶")
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir_path}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir_path}\n")
    
    for m3u_file in sorted(m3u_files):
        try:
            print(f"ğŸ”„ æ­£åœ¨å¤„ç†: {m3u_file.name}")
            
            # åŠ è½½å¹¶è§£æM3Uæ–‡ä»¶
            playlist = M3UPlaylist(str(m3u_file))
            channels = playlist.parse()
            
            # ç»Ÿè®¡è¡¥å……logoçš„é¢‘é“æ•°
            channels_with_logo_added = 0
            
            # å¦‚æœå»é‡ï¼Œæ‰§è¡Œå»é‡æ“ä½œ
            if dedup:
                dedup_result = playlist.deduplicate_urls()
                channels = playlist.channels
                print(f"  ğŸ“Š å»é‡: {dedup_result['original_count']} -> {dedup_result['deduplicated_count']} ä¸ªé¢‘é“")
            
            # æ£€æŸ¥å¹¶è¡¥å……logoï¼ˆåœ¨generate_m3uæ—¶ä¼šè‡ªåŠ¨å¤„ç†ï¼‰
            # ä½†æˆ‘ä»¬éœ€è¦å…ˆç»Ÿè®¡ä¸€ä¸‹æœ‰å¤šå°‘é¢‘é“ç¼ºå°‘logo
            no_logo_before = sum(1 for ch in channels if not ch.get('tvg-logo'))
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            output_file = output_dir_path / m3u_file.name
            
            # å¯¼å‡ºM3Uæ–‡ä»¶ï¼ˆä¼šè‡ªåŠ¨è¡¥å……logoï¼‰
            playlist.generate_m3u(str(output_file))
            
            # é‡æ–°åŠ è½½è¾“å‡ºæ–‡ä»¶ä»¥ç»Ÿè®¡è¡¥å……çš„logo
            output_playlist = M3UPlaylist(str(output_file))
            output_channels = output_playlist.parse()
            no_logo_after = sum(1 for ch in output_channels if not ch.get('tvg-logo'))
            channels_with_logo_added = no_logo_before - no_logo_after
            
            results['processed'].append({
                'input_file': m3u_file.name,
                'output_file': str(output_file),
                'channel_count': len(channels),
                'logo_added': channels_with_logo_added
            })
            
            results['total_channels'] += len(channels)
            results['channels_with_logo_added'] += channels_with_logo_added
            
            print(f"  âœ… å®Œæˆ: {len(channels)} ä¸ªé¢‘é“ï¼Œè¡¥å……äº† {channels_with_logo_added} ä¸ªlogo")
            
        except Exception as e:
            error_msg = f"å¤„ç† {m3u_file.name} å¤±è´¥: {e}"
            results['failed'].append({
                'input_file': m3u_file.name,
                'error': str(e)
            })
            print(f"  âŒ {error_msg}")
            import traceback
            traceback.print_exc()
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='M3Uæ’­æ”¾åˆ—è¡¨å¤„ç†å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è§£æM3Uæ–‡ä»¶å¹¶å¯¼å‡ºJSON
  %(prog)s input.m3u -f json

  # åˆå¹¶RTPæ–‡ä»¶å¹¶ç”Ÿæˆæ–°çš„M3U
  %(prog)s input.m3u --rtp æ¹–åŒ—ç”µä¿¡.txt -f m3u -o output.m3u

  # æ‰¹é‡å¤„ç†æ‰€æœ‰RTPæ–‡ä»¶
  %(prog)s template.m3u --batch --rtp-dir source/zubo/rtp --output-dir m3u

  # æ‰¹é‡å¤„ç†M3Uæ–‡ä»¶ï¼ˆä»ç›®å½•è¯»å–å¹¶è¾“å‡ºåˆ°å¦ä¸€ä¸ªç›®å½•ï¼‰
  %(prog)s --batch-m3u --input-dir m3u --output-dir m3u_processed

  # æ¯”è¾ƒä¸¤ä¸ªM3Uæ–‡ä»¶çš„URLå·®å¼‚
  %(prog)s file1.m3u --compare file2.m3u --compare-output report.txt
        """
    )
    
    parser.add_argument('input_file', nargs='?', help='è¾“å…¥çš„M3Uæ–‡ä»¶è·¯å¾„ï¼ˆæ‰¹é‡å¤„ç†æ—¶ä½œä¸ºæ¨¡æ¿ï¼‰')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('-f', '--format', choices=['json', 'csv', 'm3u'], 
                       default='json', help='è¾“å‡ºæ ¼å¼ï¼ˆé»˜è®¤ï¼šjsonï¼‰')
    parser.add_argument('-s', '--summary', action='store_true', 
                       help='æ˜¾ç¤ºè§£ææ‘˜è¦ä¿¡æ¯')
    parser.add_argument('--rtp', help='RTPæ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºrtpç›®å½•ï¼Œå¦‚ï¼šä¸Šæµ·å¸‚ç”µä¿¡.txtï¼‰')
    parser.add_argument('--rtp-dir', default='source/zubo/rtp', 
                       help='RTPæ–‡ä»¶ç›®å½•ï¼ˆé»˜è®¤ï¼šsource/zubo/rtpï¼‰')
    parser.add_argument('--config', default='source/zubo/data.py',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šsource/zubo/data.pyï¼‰')
    parser.add_argument('--compare', help='è¦æ¯”è¾ƒçš„ç¬¬äºŒä¸ªM3Uæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--compare-output', help='æ¯”è¾ƒç»“æœè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--batch', action='store_true',
                       help='æ‰¹é‡å¤„ç†æ¨¡å¼ï¼šå¤„ç†rtp-dirä¸­æ‰€æœ‰txtæ–‡ä»¶')
    parser.add_argument('--output-dir', default='m3u',
                       help='æ‰¹é‡å¤„ç†æ—¶çš„è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šm3uï¼‰')
    parser.add_argument('--report', help='æ‰¹é‡å¤„ç†æ—¶è¾“å‡ºç¼ºå°‘logoçš„é¢‘é“æŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--dedup', action='store_true',
                       help='å»é™¤é‡å¤çš„URLï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªå‡ºç°çš„ï¼Œä¼˜å…ˆä¿ç•™æœ‰logoçš„ï¼‰')
    parser.add_argument('--batch-m3u', action='store_true',
                       help='æ‰¹é‡å¤„ç†M3Uæ–‡ä»¶æ¨¡å¼ï¼šä»input-dirè¯»å–æ‰€æœ‰m3uæ–‡ä»¶ï¼Œå¤„ç†åè¾“å‡ºåˆ°output-dir')
    parser.add_argument('--input-dir', help='æ‰¹é‡å¤„ç†M3Uæ—¶çš„è¾“å…¥ç›®å½•')
    
    args = parser.parse_args()
    
    # æ‰¹é‡å¤„ç†M3Uæ–‡ä»¶æ¨¡å¼
    if args.batch_m3u:
        if not args.input_dir:
            parser.error("æ‰¹é‡å¤„ç†M3Uæ¨¡å¼éœ€è¦æŒ‡å®š --input-dir å‚æ•°")
        
        try:
            results = batch_process_m3u(
                args.input_dir,
                args.output_dir,
                dedup=args.dedup
            )
            
            print(f"\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ:")
            print(f"  âœ… æˆåŠŸ: {len(results['processed'])} ä¸ªæ–‡ä»¶")
            print(f"  âŒ å¤±è´¥: {len(results['failed'])} ä¸ªæ–‡ä»¶")
            print(f"  ğŸ“º æ€»é¢‘é“æ•°: {results['total_channels']}")
            print(f"  ğŸ–¼ï¸  è¡¥å……logoæ•°: {results['channels_with_logo_added']}")
            
            if results['failed']:
                print(f"\nâŒ å¤±è´¥çš„æ–‡ä»¶:")
                for item in results['failed']:
                    print(f"  - {item['input_file']}: {item['error']}")
            
            return
        
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    # æ‰¹é‡å¤„ç†RTPæ¨¡å¼
    if args.batch:
        if not args.input_file:
            parser.error("æ‰¹é‡å¤„ç†æ¨¡å¼éœ€è¦æŒ‡å®šæ¨¡æ¿M3Uæ–‡ä»¶")
        
        try:
            results = batch_process_rtp(
                args.input_file,
                args.rtp_dir,
                args.output_dir,
                args.config
            )
            
            print(f"\nğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ:")
            print(f"  âœ… æˆåŠŸ: {len(results['processed'])} ä¸ªæ–‡ä»¶")
            print(f"  âŒ å¤±è´¥: {len(results['failed'])} ä¸ªæ–‡ä»¶")
            
            if results['failed']:
                print(f"\nâŒ å¤±è´¥çš„æ–‡ä»¶:")
                for item in results['failed']:
                    print(f"  - {item['rtp_file']}: {item['error']}")
            
            # ç”Ÿæˆç¼ºå°‘logoçš„é¢‘é“æŠ¥å‘Š
            if results['no_logo_channels']:
                report_content = "ç¼ºå°‘tvg-logoçš„é¢‘é“æŠ¥å‘Š\n"
                report_content += "=" * 60 + "\n\n"
                
                for rtp_name, channels in sorted(results['no_logo_channels'].items()):
                    report_content += f"{rtp_name} ({len(channels)}ä¸ª):\n"
                    for ch in channels:
                        report_content += f"  - {ch}\n"
                    report_content += "\n"
                
                if args.report:
                    report_path = Path(args.report)
                else:
                    report_path = Path(args.output_dir) / "no_logo_report.txt"
                
                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                
                print(f"\nğŸ“ ç¼ºå°‘logoçš„é¢‘é“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
                print(f"   å…± {len(results['no_logo_channels'])} ä¸ªæ–‡ä»¶æœ‰ç¼ºå°‘logoçš„é¢‘é“")
            else:
                print(f"\nâœ… æ‰€æœ‰é¢‘é“éƒ½æœ‰logo")
            
            return
        
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    if not args.input_file:
        parser.error("éœ€è¦æŒ‡å®šinput_fileå‚æ•°")
    
    # å¦‚æœæŒ‡å®šäº†æ¯”è¾ƒæ–‡ä»¶ï¼Œæ‰§è¡Œæ¯”è¾ƒ
    if args.compare:
        print(f"ğŸ” æ­£åœ¨æ¯”è¾ƒä¸¤ä¸ªM3Uæ–‡ä»¶...")
        print(f"  æ–‡ä»¶1: {args.input_file}")
        print(f"  æ–‡ä»¶2: {args.compare}")
        
        try:
            result = M3UComparator.compare(
                args.input_file,
                args.compare,
                output_file=args.compare_output,
                config_file=args.config
            )
            
            print(f"\nğŸ“Š æ¯”è¾ƒç»“æœ:")
            print(f"  æ–‡ä»¶1æ€»é¢‘é“æ•°: {result['file1_total']}")
            print(f"  æ–‡ä»¶2æ€»é¢‘é“æ•°: {result['file2_total']}")
            print(f"  âœ… URLç›¸åŒçš„é¢‘é“: {result['same_count']}")
            print(f"  âš ï¸  URLä¸åŒçš„é¢‘é“: {result['diff_count']}")
            print(f"  ğŸ“„ ä»…åœ¨æ–‡ä»¶1ä¸­çš„é¢‘é“: {result['only_file1_count']}")
            print(f"  ğŸ“„ ä»…åœ¨æ–‡ä»¶2ä¸­çš„é¢‘é“: {result['only_file2_count']}")
            
            if result['differences']:
                print(f"\nğŸ”´ URLä¸åŒçš„é¢‘é“åˆ—è¡¨ (å‰10ä¸ª):")
                for i, diff in enumerate(result['differences'][:10], 1):
                    print(f"  {i}. {diff['name']}")
                    print(f"     æ–‡ä»¶1: {diff['file1_urls'][0]}")
                    print(f"     æ–‡ä»¶2: {diff['file2_urls'][0]}")
                if len(result['differences']) > 10:
                    print(f"     ... è¿˜æœ‰ {len(result['differences']) - 10} ä¸ªå·®å¼‚")
            
            if args.compare_output:
                print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.compare_output}")
            else:
                print(f"\nğŸ’¡ æç¤º: ä½¿ç”¨ --compare-output å‚æ•°å¯ä¿å­˜è¯¦ç»†æŠ¥å‘Š")
            
            return
        
        except Exception as e:
            print(f"âŒ æ¯”è¾ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    # å¦‚æœæŒ‡å®šäº†æ¯”è¾ƒæ–‡ä»¶ï¼Œæ‰§è¡Œæ¯”è¾ƒ
    if args.compare:
        print(f"ğŸ” æ­£åœ¨æ¯”è¾ƒä¸¤ä¸ªM3Uæ–‡ä»¶...")
        print(f"  æ–‡ä»¶1: {args.input_file}")
        print(f"  æ–‡ä»¶2: {args.compare}")
        
        try:
            result = M3UComparator.compare(
                args.input_file,
                args.compare,
                output_file=args.compare_output,
                config_file=args.config
            )
            
            print(f"\nğŸ“Š æ¯”è¾ƒç»“æœ:")
            print(f"  æ–‡ä»¶1æ€»é¢‘é“æ•°: {result['file1_total']}")
            print(f"  æ–‡ä»¶2æ€»é¢‘é“æ•°: {result['file2_total']}")
            print(f"  âœ… URLç›¸åŒçš„é¢‘é“: {result['same_count']}")
            print(f"  âš ï¸  URLä¸åŒçš„é¢‘é“: {result['diff_count']}")
            print(f"  ğŸ“„ ä»…åœ¨æ–‡ä»¶1ä¸­çš„é¢‘é“: {result['only_file1_count']}")
            print(f"  ğŸ“„ ä»…åœ¨æ–‡ä»¶2ä¸­çš„é¢‘é“: {result['only_file2_count']}")
            
            if result['differences']:
                print(f"\nğŸ”´ URLä¸åŒçš„é¢‘é“åˆ—è¡¨ (å‰10ä¸ª):")
                for i, diff in enumerate(result['differences'][:10], 1):
                    print(f"  {i}. {diff['name']}")
                    print(f"     æ–‡ä»¶1: {diff['file1_urls'][0]}")
                    print(f"     æ–‡ä»¶2: {diff['file2_urls'][0]}")
                if len(result['differences']) > 10:
                    print(f"     ... è¿˜æœ‰ {len(result['differences']) - 10} ä¸ªå·®å¼‚")
            
            if args.compare_output:
                print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.compare_output}")
            else:
                print(f"\nğŸ’¡ æç¤º: ä½¿ç”¨ --compare-output å‚æ•°å¯ä¿å­˜è¯¦ç»†æŠ¥å‘Š")
            
            return
        
        except Exception as e:
            print(f"âŒ æ¯”è¾ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    # è§£æM3Uæ–‡ä»¶
    playlist = M3UPlaylist(args.input_file)
    channels = playlist.parse()
    
    print(f"âœ… æˆåŠŸè§£æ {len(channels)} ä¸ªé¢‘é“")
    
    # å¦‚æœæŒ‡å®šäº†å»é‡ï¼Œæ‰§è¡Œå»é‡
    if args.dedup:
        print(f"\nğŸ”„ æ­£åœ¨å»é™¤é‡å¤çš„URL...")
        try:
            dedup_result = playlist.deduplicate_urls()
            print(f"âœ… å»é‡å®Œæˆ:")
            print(f"  åŸå§‹é¢‘é“æ•°: {dedup_result['original_count']}")
            print(f"  å»é‡åé¢‘é“æ•°: {dedup_result['deduplicated_count']}")
            print(f"  ç§»é™¤é‡å¤é¢‘é“æ•°: {dedup_result['removed_count']}")
            
            if dedup_result['removed_channels']:
                print(f"\nğŸ“‹ ç§»é™¤çš„é¢‘é“åˆ—è¡¨ (å‰10ä¸ª):")
                for i, ch in enumerate(dedup_result['removed_channels'][:10], 1):
                    print(f"  {i}. {ch['name']} - {ch['reason']}")
                    print(f"     URL: {ch['url']}")
                if len(dedup_result['removed_channels']) > 10:
                    print(f"     ... è¿˜æœ‰ {len(dedup_result['removed_channels']) - 10} ä¸ªè¢«ç§»é™¤çš„é¢‘é“")
            
            channels = playlist.channels
        except Exception as e:
            print(f"âŒ å»é‡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    # å¦‚æœæŒ‡å®šäº†RTPæ–‡ä»¶ï¼Œè¿›è¡Œåˆå¹¶
    if args.rtp:
        print(f"\nğŸ”„ æ­£åœ¨åˆå¹¶RTPæ–‡ä»¶: {args.rtp}")
        try:
            channels = playlist.merge_with_rtp(
                args.rtp,
                rtp_dir=args.rtp_dir,
                config_file=args.config
            )
            print(f"âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(channels)} ä¸ªé¢‘é“ï¼ˆåŒ…å«æ–°å¢çš„RTPé¢‘é“ï¼‰")
        except Exception as e:
            print(f"âŒ åˆå¹¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    # æ˜¾ç¤ºæ‘˜è¦
    if args.summary:
        summary = playlist.get_summary()
        print("\nğŸ“Š è§£ææ‘˜è¦:")
        print(f"  æ€»é¢‘é“æ•°: {summary['total_channels']}")
        print(f"  æœ‰tvg-nameçš„é¢‘é“: {summary['channels_with_name']}")
        print(f"  æœ‰tvg-logoçš„é¢‘é“: {summary['channels_with_logo']}")
        print(f"  æœ‰URLçš„é¢‘é“: {summary['channels_with_url']}")
        print(f"\nğŸ“ åˆ†ç»„ç»Ÿè®¡:")
        for group, count in sorted(summary['group_titles'].items()):
            print(f"  {group}: {count}")
    
    # å¯¼å‡ºæ–‡ä»¶
    if args.format == 'json':
        output_path = playlist.export_to_json(args.output)
        print(f"\nğŸ’¾ å·²å¯¼å‡ºJSONæ–‡ä»¶: {output_path}")
    elif args.format == 'csv':
        output_path = playlist.export_to_csv(args.output)
        print(f"\nğŸ’¾ å·²å¯¼å‡ºCSVæ–‡ä»¶: {output_path}")
    elif args.format == 'm3u':
        output_path = playlist.generate_m3u(args.output)
        print(f"\nğŸ’¾ å·²ç”ŸæˆM3Uæ–‡ä»¶: {output_path}")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªé¢‘é“ç¤ºä¾‹
    if channels:
        print(f"\nğŸ“º å‰3ä¸ªé¢‘é“ç¤ºä¾‹:")
        for i, channel in enumerate(channels[:3], 1):
            print(f"  {i}. {channel.get('tvg-name', 'N/A')} (ID: {channel.get('tvg-id', 'N/A')})")
            print(f"     Logo: {channel.get('tvg-logo', 'N/A')}")
            print(f"     åˆ†ç»„: {channel.get('group-title', 'N/A')}")
            url = channel.get('url', 'N/A')
            if len(url) > 60:
                url = url[:60] + '...'
            print(f"     URL: {url}")


if __name__ == '__main__':
    main()
